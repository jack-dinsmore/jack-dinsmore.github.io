<html>
<head>
    <meta charset="utf-8">
    <link rel="stylesheet" type = "text/css" href = "https://jack-dinsmore.github.io/blog/html/css/text.css">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async
            src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js">
    </script>
    <script>
window.MathJax = {
    tex: {
        macros: {
            bm: ["\\mathbf {#1}",1],
            parens: ["\\left( #1 \\right)", 1],
            braces: ["\\left\{ #1 \\right\}", 1],
            brackets: ["\\left[ #1 \\right]", 1],
            eval: ["\\left. #1 \\right|", 1],
            fraci: ["{#1} / {#2}", 2],
            expp: ["\\exp\\left( #1 \right)", 1],
            bra: ["\\left\\langle #1 \\right|", 1],
            ket: ["\\left| #1 \\right\\rangle", 1],
            braket: ["\\langle {#1} | {#2} \\rangle", 2],
        }
    }
}
    </script>
    <title>statistics</title>
</head><body><div id="content"><h2><a href="https://jack-dinsmore.github.io/blog/html/index.html">Home</a></h2><h1>General Bayesian Fitting: Markov Chain Monte Carlo methods</h1>

<p>We have gone through several blog posts about fitting now, from <a href=https://jack-dinsmore.github.io/blog/html/parameter%2dfitting.html>general theory</a> to <a href=https://jack-dinsmore.github.io/blog/html/line.html>an example for linear functions</a> to <a href=https://jack-dinsmore.github.io/blog/html/line2.html>establishing uncertainties on the best fit</a> and <a href=https://jack-dinsmore.github.io/blog/html/gaussian.html>a generalization to Gaussian likelihoods</a>. All of these posts invoked assumptions to keep the calculations tractable, but these assumptions can be (and often are) removed with the help of new algorithms, such as the <i>Markov Chain Monte Carlo</i> (MCMC) methods we’ll introduce here.
</p>
<button class="collapsible"><h2>Motivations</h2></button><div class="section">

<p>To understand MCMCs, we’ll have to approach parameter fitting in a completely new way, which deserves some introduction. Let’s start by stating the easy part. There’s nothing fundamentally hard about computing the posterior \(P(\bm \theta | D) = \mathcal{L}(\bm \theta) \pi(\bm \theta)\). We are simply multiplying the known functions: the likelihood and the prior. But practical issues arrive in two forms. Likelihoods can be slow to compute, and one often wishes to know \(P(\bm \theta | D)\) at many values of \(\bm \theta\), so that one can be sure one has found the minimum and has fully understood the shape of the distribution. The trick is to use an algorithm which spends its time calculating \(P(\bm \theta|D)\) only at the interesting points, i.e. near the maximum.
</p>
<p>This efficient computation of \(P(\bm \theta |D )\) is one goal of an MCMC, which we will introduce in this post. But there is another goal too, which is to generate <i>samples</i> from \(P(\bm \theta|D)\). We haven’t thought much about sampling distributions yet, since we’ve so far only fitted for the functional forms of our posteriors. But if the posterior is some awful many-parameter function, a functional form might not be useful or even desireable. Ultimately, we want to know things such as the mean, median, modes, and credible intervals of a distribution. To compute these from functional forms, you need to do integrals or invert functions in general, both of which are hard problems. But the tasks are easy if you have samples. The distribution mean is just the mean of all the samples; the median is the sample median, and the credible intervals have to do with the samples’ percentiles. If we really need the form of the posterior, you can always histogram the samples and the curve represents \(P(\bm \theta | D)\). This act of understanding something by probabilistically generating samples from it is called a <i>Monte Carlo</i> method (the second MCMC). 
</p>
<p>Since we need both to navigate our way to the maximum of a posterior and to generate samples from it, it makes sense to solve both these problems with one algorithm. Our algorithm can generate samples at the same time as it traverses the posterior. This is rather like the minimization algorithms we introduced in the previous post, except now we’re proposing to record the points visited by the algorithm as samples. The first few samples will be dependent on where the algorithm starts, but after the algorithm approaches the minimum they will start to reflect the true distribution of the posterior near the maximum. This trick of recording the <code></code>path<code></code> of an algorithm through parameter space is the other MC: the list of samples generated is called a <i>Markov Chain</i>. 
</p>
<p>The challenge is to make sure that the algorithm really does visit points in proportion to the probability there, without favoring some over others. This is not true of any of the minimization algorithms we’ve discussed so far, but now we’ll discuss a simple new one which guarantees unbiased samples.
</p>
</div> <button class="collapsible"><h2>Metropolis-Hastings algorithm</h2></button><div class="section">

<p>The Metropolis-Hastings algorithm is one of the simplest ways to generate correct MCMC samples from a distribution. It works like this.
</p>
<p>Consider a single Markov chain, whose most recent point is \(x_n\). You wish to generate the next point \(\bm \theta_{n+1}\) which is distributed according to the posterior \(P(\bm \theta)\). The algorithm proceeds by first choosing a random trial point \(\bm \phi\) and then generating a uniformly random number \(r\) from 0 to 1. If \(r < P(\bm \phi)/P(\bm \theta_n)\), then the trial point is accepted and \(\bm \theta_{n+1}\) is set to \(\bm \phi\). Otherwise, reject the point and set \(\bm \theta_{n+1}=\bm \theta_n\).
</p>
<p>If \(\bm \phi\) is more probable than \(P_n\) (\(P(\bm \phi) > P(\bm \theta_n)\)), this algorithm guarantees that \(\bm \phi\) is always accepted. But the power of the Metropolis-Hastings algorithm lies in the fact that it also has a chance to accept <i>less</i> probable values. This is fundamentally different behavior from a minimizer, which has no reason to ever progress backwards in this way. The Metropolis-Hastings algorithm is trying to do something more: identify the shape of all of \(P(\bm \theta)\), and accepting a few low probability values of \(\bm \phi\) ensures that the tails of the \(P(\bm \phi)\) distribution are accurately modeled.
</p>
<p>To prove that the Metropolis-Hastings algorithm is correct, imagine that we’re running lots of Markov chains at the same time, which have reached steady state. The algorithm has converged (reached steady state) when the number of points entering some region \(d\bm \theta\) is equal to the number of points exiting \(d\bm \theta\). The number of points exiting a region is the number of points in that region \(N(\bm \theta)\) times the probability to exit, and the Metropolis-Hastings algorithm dictates that the probability to exit to point \(\bm \phi\) is \(\min(P(\bm \phi)/P(\bm \theta),1)\) (the minimum appears because the probability to exit cannot be more than 1, even if \(P(\bm \phi) > P(\bm \theta)\)). Suppose \(P(\bm \phi) > P(\bm \theta)\). The steady-state condition is
<div class="eq"><div class="eqtext">\[N(\bm \theta) = N(\bm \phi)\frac{P(\bm \theta)}{P(\bm \phi)}.\]</div><div class="eqnum" id="eq1">(1)</div></div>
What value of \(N\) satisfies this condition? Simply \(N(\bm \theta) \propto P(\bm \theta)\). The chains will be distributed according to the target probability distribution! In fact, \(N(\bm \theta) \propto P(\bm \theta)\) is the only end-state that satisfies this condition for all pairs of points \(\bm \phi\) and \(\bm \theta\).
</p>
<p>This conclusion proves that, when the Metropolis-Hastings algorithm has converged, its Markov chain contains correct samples. However, we haven’t proved that the algorithm converges at a reasonable rate. Much of the technology of complicated fitters goes into hastening the process of convergence, mostly by choosing clever trial values \(\bm \phi\). We’ll discuss some of these in the next section.
</p>
</div> <button class="collapsible"><h2>Choosing the trial point \(\bm \phi\)</h2></button><div class="section">


</div> <button class="collapsible"><h2>Conclusion</h2></button><div class="section">

<p>Mention that MCMCs are inefficient minimizers.
</div></div><div id="footer">
Copyright &copy; 2024 Jack Dinsmore. &emsp;Updated July 7. &emsp;Version 0.1</div></body>
<script>
var coll = document.getElementsByClassName("collapsible");
var i;

for (i = 0; i < coll.length; i++) {{
    coll[i].addEventListener("click", function() {{
        this.classList.toggle("active");
        var content = this.nextElementSibling;
        if (content.style.maxHeight === "0px"){{
            content.style.maxHeight = content.scrollHeight+"px";
        }} else {{
            content.style.maxHeight = "0px";
        }}
    }});
}}
</script></html>
